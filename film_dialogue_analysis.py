# -*- coding: utf-8 -*-
"""FIlm_Dialogue_Analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X7N2cqFGkcTKcXN2SUnVaDcgmM3-hHlH
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import nltk

from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import LabelEncoder, MinMaxScaler, OneHotEncoder
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score

df = pd.read_csv('movie_characters_metadata.tsv', sep='\t', error_bad_lines=False, header=None)
lines_df = pd.read_csv('movie_lines.tsv', sep='\t', error_bad_lines=False, header=None)

df.columns = ['chID', "Name", "movieID", "mtitle", "gender", "position"]

df.gender.value_counts()

df = df[df.gender != '?']
df.gender.value_counts()

df = df[df.gender != '?']
df.gender = df.gender.apply(lambda g: 0 if g in ['m', 'M'] else 1)
df.shape

df.gender.value_counts()

df.position = df.position.apply(lambda value: "10+" if not value in ['1', '2', '3', '4', '5', '6', '7', '8', '9'] else value)
df.position.value_counts()

lines_df.columns = ["lineID", "chID", "movieID", "Name", "Dialogue"]
lines_df.head(10)

lines_df = lines_df.dropna(subset="Dialogue")
lines_df.head(10)

df = pd.merge(lines_df, df, how = 'inner', on = ['chID', 'movieID', 'Name'])

pd.set_option('display.width', 3000)
df.head()

def clean_texts( text ):

    letters_only = re.sub("[^a-zA-Z]", " ", text)

    words = letters_only.lower().split()
    stops = set(stopwords.words("english"))
    ps = PorterStemmer()

    dialogue = [ps.stem(w) for w in words if not w in stops]

    dialogue = ' '.join(dialogue)
    return dialogue

df['cleaned_dialogue'] = df['Dialogue'].apply(clean_texts)

df.head()

df['linelength'] = df.Dialogue.str.len()
df['wordcount'] = df.Dialogue.str.count(' ') + 1
df.head()

df = df.groupby(['chID', 'movieID', 'Name', 'gender', 'position']).agg({'linelength' : ['median'],
                 'wordcount' : ['median'],
                 'chID' : ['count'],
                 'cleaned_dialogue' : [lambda x : ' '.join(x)]
                })

df.columns = ["_".join(x) for x in df.columns.ravel()]
df.reset_index(inplace=True)

df.head()

y = df['gender']
X = df.copy()
X.drop('gender', axis=1, inplace=True)

## Removing unnecessary columns
X.drop('chID', axis=1, inplace=True)
X.drop('movieID', axis=1, inplace=True)
X.drop('Name', axis=1, inplace=True)
X.head()

y.head()

y.value_counts()

from imblearn.under_sampling import RandomUnderSampler

undersample = RandomUnderSampler(sampling_strategy='majority')
X_under, y_under = undersample.fit_resample(X, y)
y_under.value_counts()

X_train, X_test, y_train, y_test = train_test_split(X_under, y_under, test_size=0.2, random_state = 10, stratify=y_under)

class Converter(BaseEstimator, TransformerMixin):

    def fit(self, x, y=None):
        return self

    def transform(self, data_frame):
        return data_frame.values.ravel()

numeric_features = ['linelength_median', 'wordcount_median', 'chID_count']

numeric_transformer = Pipeline(steps=[('scaler', MinMaxScaler())])

categorical_features = ['position']
categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))])

vectorizer_features = ['cleaned_dialogue_<lambda>']
vectorizer_transformer = Pipeline(steps=[
    ('con', Converter()),
    ('tf', TfidfVectorizer())])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features),
        ('vec', vectorizer_transformer, vectorizer_features)])
log_clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', LogisticRegression())])

nb_clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', MultinomialNB())])

rf_clf = Pipeline(steps=[('preprocessor', preprocessor),
                      ('classifier', RandomForestClassifier(n_estimators=120, min_samples_leaf=10,
                                                            max_features=0.7, n_jobs=-1, oob_score=True))])

log_clf.fit(X_train, y_train)
nb_clf.fit(X_train, y_train)
rf_clf.fit(X_train, y_train)

y_pred = rf_clf.predict(X_test)
cm = confusion_matrix(y_test, y_pred)
print(cm)
accuracy_score(y_test, y_pred)

importance = rf_clf.feature_importances_